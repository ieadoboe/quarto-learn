<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.23">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Reinforcement Learning Expanded Introduction – Not That Deep</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-226bd0f977fa82dfae4534cac220d79a.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-a7149113d679ca37912618eec6fbd8f1.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-sidebar floating nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../assets/logo.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Not That Deep</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">Welcome</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../lessons/index.html"> 
<span class="menu-text">Lessons</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://ieadoboe.github.io/" target="_blank"> 
<span class="menu-text">About Me</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../lessons/expert/1-rl-fundamentals.html">Cutting-Edge Techniques</a></li><li class="breadcrumb-item"><a href="../../lessons/expert/1-rl-part-2.html">Reinforcement Learning Expanded Introduction</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Data Science Foundations</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lessons/beginner/basic-concepts-and-terms.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Basic Concepts and Terms</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Neural Networks Fundamentals</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lessons/intermediate/perceptrons-activation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">perceptrons-activation</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Advanced Deep Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lessons/advanced/advanced-cnns.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">advanced-cnns</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Cutting-Edge Techniques</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lessons/expert/1-rl-fundamentals.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Reinforcement Learning Introduction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lessons/expert/1-rl-part-2.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Reinforcement Learning Expanded Introduction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lessons/expert/2-bandit-algos.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bandit Algorithms</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lessons/expert/3-markov-decision-process.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Markov Decision Process (MDP)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lessons/expert/4-episodes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Episodes in Reinforcement Learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../lessons/expert/5-dynamic-programming.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Dynamic Programming in Reinforcement Learning</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#what-is-reinforcement-learning" id="toc-what-is-reinforcement-learning" class="nav-link active" data-scroll-target="#what-is-reinforcement-learning">What is Reinforcement Learning?</a></li>
  <li><a href="#the-rl-framework-agent-environment-interaction" id="toc-the-rl-framework-agent-environment-interaction" class="nav-link" data-scroll-target="#the-rl-framework-agent-environment-interaction">The RL Framework: Agent-Environment Interaction</a>
  <ul class="collapse">
  <li><a href="#core-components" id="toc-core-components" class="nav-link" data-scroll-target="#core-components">Core Components</a></li>
  <li><a href="#the-markov-property-why-states-matter" id="toc-the-markov-property-why-states-matter" class="nav-link" data-scroll-target="#the-markov-property-why-states-matter">The Markov Property: Why States Matter</a></li>
  </ul></li>
  <li><a href="#policies-and-value-functions" id="toc-policies-and-value-functions" class="nav-link" data-scroll-target="#policies-and-value-functions">Policies and Value Functions</a>
  <ul class="collapse">
  <li><a href="#policy-pi" id="toc-policy-pi" class="nav-link" data-scroll-target="#policy-pi">Policy (<span class="math inline">\pi</span>)</a></li>
  <li><a href="#value-functions-measuring-long-term-success" id="toc-value-functions-measuring-long-term-success" class="nav-link" data-scroll-target="#value-functions-measuring-long-term-success">Value Functions: Measuring Long-term Success</a></li>
  <li><a href="#action-value-function-q-function" id="toc-action-value-function-q-function" class="nav-link" data-scroll-target="#action-value-function-q-function">Action-Value Function (Q-function)</a></li>
  </ul></li>
  <li><a href="#the-optimal-policy" id="toc-the-optimal-policy" class="nav-link" data-scroll-target="#the-optimal-policy">The Optimal Policy</a></li>
  <li><a href="#exploration-vs.-exploitation-the-central-dilemma" id="toc-exploration-vs.-exploitation-the-central-dilemma" class="nav-link" data-scroll-target="#exploration-vs.-exploitation-the-central-dilemma">Exploration vs.&nbsp;Exploitation: The Central Dilemma</a>
  <ul class="collapse">
  <li><a href="#epsilon-greedy-strategy" id="toc-epsilon-greedy-strategy" class="nav-link" data-scroll-target="#epsilon-greedy-strategy">Epsilon-Greedy Strategy</a></li>
  </ul></li>
  <li><a href="#multi-armed-bandits-rl-without-states" id="toc-multi-armed-bandits-rl-without-states" class="nav-link" data-scroll-target="#multi-armed-bandits-rl-without-states">Multi-Armed Bandits: RL Without States</a>
  <ul class="collapse">
  <li><a href="#upper-confidence-bound-ucb" id="toc-upper-confidence-bound-ucb" class="nav-link" data-scroll-target="#upper-confidence-bound-ucb">Upper Confidence Bound (UCB)</a></li>
  </ul></li>
  <li><a href="#learning-approaches" id="toc-learning-approaches" class="nav-link" data-scroll-target="#learning-approaches">Learning Approaches</a>
  <ul class="collapse">
  <li><a href="#model-based-vs.-model-free" id="toc-model-based-vs.-model-free" class="nav-link" data-scroll-target="#model-based-vs.-model-free">Model-Based vs.&nbsp;Model-Free</a></li>
  <li><a href="#temporal-difference-learning" id="toc-temporal-difference-learning" class="nav-link" data-scroll-target="#temporal-difference-learning">Temporal Difference Learning</a></li>
  </ul></li>
  <li><a href="#common-pitfalls-and-misconceptions" id="toc-common-pitfalls-and-misconceptions" class="nav-link" data-scroll-target="#common-pitfalls-and-misconceptions">Common Pitfalls and Misconceptions</a></li>
  <li><a href="#real-world-applications" id="toc-real-world-applications" class="nav-link" data-scroll-target="#real-world-applications">Real-World Applications</a></li>
  <li><a href="#key-takeaways" id="toc-key-takeaways" class="nav-link" data-scroll-target="#key-takeaways">Key Takeaways</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../lessons/expert/1-rl-fundamentals.html">Cutting-Edge Techniques</a></li><li class="breadcrumb-item"><a href="../../lessons/expert/1-rl-part-2.html">Reinforcement Learning Expanded Introduction</a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">Reinforcement Learning Expanded Introduction</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="what-is-reinforcement-learning" class="level2">
<h2 class="anchored" data-anchor-id="what-is-reinforcement-learning">What is Reinforcement Learning?</h2>
<p>Reinforcement learning (RL) is a framework for learning optimal behavior through trial-and-error interaction with an environment. Unlike supervised learning (where we have correct answers) or unsupervised learning (where we find patterns), RL learns from rewards and penalties.</p>
<p><strong>Think of it like learning to drive:</strong> You don’t get a manual with every possible scenario - instead, you learn by trying actions (steering, braking) and experiencing consequences (smooth ride, honking horns, accidents). Over time, you develop a driving policy that maximizes good outcomes.</p>
</section>
<section id="the-rl-framework-agent-environment-interaction" class="level2">
<h2 class="anchored" data-anchor-id="the-rl-framework-agent-environment-interaction">The RL Framework: Agent-Environment Interaction</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://via.placeholder.com/500x300/4a90e2/ffffff?text=Agent-Environment+Interaction+Loop.png" class="img-fluid figure-img"></p>
<figcaption>RL Agent-Environment Loop</figcaption>
</figure>
</div>
<p><em>Figure 1: The fundamental RL loop where an agent takes actions in an environment and receives observations and rewards</em></p>
<section id="core-components" class="level3">
<h3 class="anchored" data-anchor-id="core-components">Core Components</h3>
<p><strong>Agent</strong>: The learner/decision-maker (you, the driver)<br>
<strong>Environment</strong>: Everything outside the agent (road, other cars, traffic laws)<br>
<strong>State (<span class="math inline">s_t</span>)</strong>: The true state of the environment at time t (positions of all cars, traffic light status)<br>
<strong>Observation (<span class="math inline">o_t</span>)</strong>: What the agent actually perceives (what you see through your windshield)<br>
<strong>Action (<span class="math inline">a_t</span>)</strong>: Choice made by the agent (turn left, brake, accelerate)<br>
<strong>Reward (<span class="math inline">r_t</span>)</strong>: Feedback signal from environment (+1 for reaching destination, -100 for accident)</p>
</section>
<section id="the-markov-property-why-states-matter" class="level3">
<h3 class="anchored" data-anchor-id="the-markov-property-why-states-matter">The Markov Property: Why States Matter</h3>
<p><strong>Key assumption</strong>: The future depends only on the current state, not the entire history.</p>
<p><span class="math display">P(s_{t+1} | s_t, a_t, s_{t-1}, a_{t-1}, ...) = P(s_{t+1} | s_t, a_t)</span></p>
<p><strong>Driving analogy</strong>: To predict what happens next, you only need to know current positions and speeds, not how cars got there. This makes the problem tractable - otherwise we’d need infinite memory.</p>
</section>
</section>
<section id="policies-and-value-functions" class="level2">
<h2 class="anchored" data-anchor-id="policies-and-value-functions">Policies and Value Functions</h2>
<section id="policy-pi" class="level3">
<h3 class="anchored" data-anchor-id="policy-pi">Policy (<span class="math inline">\pi</span>)</h3>
<p>A policy maps states to actions: <span class="math inline">\pi(a|s) = P(A_t = a | S_t = s)</span></p>
<ul>
<li><strong>Deterministic policy</strong>: <span class="math inline">a = \pi(s)</span> (always take same action in same state)</li>
<li><strong>Stochastic policy</strong>: <span class="math inline">\pi(a|s)</span> (probability distribution over actions)</li>
</ul>
</section>
<section id="value-functions-measuring-long-term-success" class="level3">
<h3 class="anchored" data-anchor-id="value-functions-measuring-long-term-success">Value Functions: Measuring Long-term Success</h3>
<p>The <strong>state value function</strong> measures expected cumulative discounted reward:</p>
<p><span class="math display">V^\pi(s) = \mathbb{E}_\pi\left[\sum_{k=0}^{\infty} \gamma^k R_{t+k+1} \mid S_t = s\right]</span></p>
<p>Where: - <span class="math inline">\gamma \in [0,1]</span> is the <strong>discount factor</strong> (future rewards matter less) - <span class="math inline">R_{t+k+1}</span> is the reward at time <span class="math inline">t+k+1</span></p>
<p><strong>Why discounting?</strong> 1. Uncertainty increases with time 2. Immediate rewards often preferred (bird in hand…) 3. Mathematical convenience (prevents infinite sums)</p>
</section>
<section id="action-value-function-q-function" class="level3">
<h3 class="anchored" data-anchor-id="action-value-function-q-function">Action-Value Function (Q-function)</h3>
<p><span class="math display">Q^\pi(s,a) = \mathbb{E}_\pi\left[\sum_{k=0}^{\infty} \gamma^k R_{t+k+1} \mid S_t = s, A_t = a\right]</span></p>
<p>This tells us: “How good is taking action <span class="math inline">a</span> in state <span class="math inline">s</span>, then following policy <span class="math inline">\pi</span>?”</p>
</section>
</section>
<section id="the-optimal-policy" class="level2">
<h2 class="anchored" data-anchor-id="the-optimal-policy">The Optimal Policy</h2>
<p>We seek the policy that maximizes expected return:</p>
<p><span class="math display">\pi^* = \arg\max_\pi \mathbb{E}_{s_0 \sim \rho}[V^\pi(s_0)]</span></p>
<p>Where <span class="math inline">\rho</span> is the distribution over initial states.</p>
<p><strong>Bellman Optimality Equation:</strong> <span class="math display">V^*(s) = \max_a \sum_{s'} P(s'|s,a)[R(s,a,s') + \gamma V^*(s')]</span></p>
<p>This recursive relationship is the foundation of many RL algorithms.</p>
</section>
<section id="exploration-vs.-exploitation-the-central-dilemma" class="level2">
<h2 class="anchored" data-anchor-id="exploration-vs.-exploitation-the-central-dilemma">Exploration vs.&nbsp;Exploitation: The Central Dilemma</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://via.placeholder.com/500x250/e74c3c/ffffff?text=Exploration+vs+Exploitation+Trade-off.png" class="img-fluid figure-img"></p>
<figcaption>Exploration vs Exploitation Trade-off</figcaption>
</figure>
</div>
<p><em>Figure 2: The exploration-exploitation dilemma - balancing trying new actions vs.&nbsp;using known good actions</em></p>
<p><strong>The dilemma</strong>: Should you:<br>
- <strong>Exploit</strong>: Use current knowledge to maximize immediate reward<br>
- <strong>Explore</strong>: Try new actions to potentially find better options</p>
<p><strong>Restaurant analogy</strong>: You know one good restaurant (exploit) but there might be amazing places you haven’t tried (explore). Pure exploitation means you might miss the best restaurant in town. Pure exploration means constantly eating at mediocre new places.</p>
<section id="epsilon-greedy-strategy" class="level3">
<h3 class="anchored" data-anchor-id="epsilon-greedy-strategy">Epsilon-Greedy Strategy</h3>
<ul>
<li>With probability <span class="math inline">1-\epsilon</span>: choose best known action (exploit)</li>
<li>With probability <span class="math inline">\epsilon</span>: choose random action (explore)</li>
</ul>
</section>
</section>
<section id="multi-armed-bandits-rl-without-states" class="level2">
<h2 class="anchored" data-anchor-id="multi-armed-bandits-rl-without-states">Multi-Armed Bandits: RL Without States</h2>
<p>Bandits are a special case where: - No state transitions (each action is independent) - No temporal dependencies - Pure exploration vs.&nbsp;exploitation problem</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://via.placeholder.com/400x200/9b59b6/ffffff?text=Multi-Armed+Bandit+Problem.png" class="img-fluid figure-img"></p>
<figcaption>Multi-Armed Bandit</figcaption>
</figure>
</div>
<p><em>Figure 3: Multi-armed bandit - multiple slot machines with unknown payout rates</em></p>
<p><strong>Key difference from full RL</strong>: In bandits, your choice of slot machine doesn’t affect which machines are available next. In full RL, your actions change the state and future options.</p>
<section id="upper-confidence-bound-ucb" class="level3">
<h3 class="anchored" data-anchor-id="upper-confidence-bound-ucb">Upper Confidence Bound (UCB)</h3>
<p>Choose action that maximizes: <span class="math display">\hat{\mu}_a + \sqrt{\frac{2\ln t}{n_a}}</span></p>
<p>Where: - <span class="math inline">\hat{\mu}_a</span> = estimated mean reward for action <span class="math inline">a</span> - <span class="math inline">n_a</span> = number of times action <span class="math inline">a</span> was chosen - <span class="math inline">t</span> = total number of rounds</p>
<p>The square root term represents uncertainty - actions tried less often get exploration bonus.</p>
</section>
</section>
<section id="learning-approaches" class="level2">
<h2 class="anchored" data-anchor-id="learning-approaches">Learning Approaches</h2>
<section id="model-based-vs.-model-free" class="level3">
<h3 class="anchored" data-anchor-id="model-based-vs.-model-free">Model-Based vs.&nbsp;Model-Free</h3>
<p><strong>Model-Based</strong>: Learn environment dynamics <span class="math inline">P(s'|s,a)</span> and <span class="math inline">R(s,a)</span>, then plan - Like studying road maps before driving - Can be sample efficient but computationally expensive</p>
<p><strong>Model-Free</strong>: Learn policy/values directly from experience - Like learning to drive just by practicing - Less sample efficient but often more practical</p>
</section>
<section id="temporal-difference-learning" class="level3">
<h3 class="anchored" data-anchor-id="temporal-difference-learning">Temporal Difference Learning</h3>
<p><strong>Key insight</strong>: We don’t need to wait until episode ends to learn!</p>
<p><strong>TD Error</strong>: <span class="math inline">\delta_t = r_{t+1} + \gamma V(s_{t+1}) - V(s_t)</span></p>
<p><strong>Q-Learning Update</strong>: <span class="math display">Q(s_t, a_t) \leftarrow Q(s_t, a_t) + \alpha[r_{t+1} + \gamma \max_a Q(s_{t+1}, a) - Q(s_t, a_t)]</span></p>
<p>This lets us learn from every single step, not just complete episodes.</p>
</section>
</section>
<section id="common-pitfalls-and-misconceptions" class="level2">
<h2 class="anchored" data-anchor-id="common-pitfalls-and-misconceptions">Common Pitfalls and Misconceptions</h2>
<ol type="1">
<li><strong>State vs.&nbsp;Observation confusion</strong>: The agent rarely sees the full state</li>
<li><strong>Assuming deterministic environments</strong>: Most real environments have randomness</li>
<li><strong>Ignoring exploration</strong>: Greedy policies often get stuck in local optima</li>
<li><strong>Reward hacking</strong>: Agents optimize exactly what you specify, not what you intend</li>
</ol>
</section>
<section id="real-world-applications" class="level2">
<h2 class="anchored" data-anchor-id="real-world-applications">Real-World Applications</h2>
<ul>
<li><strong>Autonomous driving</strong>: States = traffic situations, Actions = steering/speed control</li>
<li><strong>Game playing</strong>: AlphaGo, StarCraft II agents</li>
<li><strong>Recommendation systems</strong>: States = user preferences, Actions = what to recommend</li>
<li><strong>Resource allocation</strong>: Cloud computing, power grid management</li>
<li><strong>Robotics</strong>: Learning motor skills, manipulation</li>
</ul>
</section>
<section id="key-takeaways" class="level2">
<h2 class="anchored" data-anchor-id="key-takeaways">Key Takeaways</h2>
<ol type="1">
<li>RL solves sequential decision problems through trial-and-error</li>
<li>The Markov property makes problems tractable</li>
<li>Balancing exploration and exploitation is crucial</li>
<li>Value functions capture long-term consequences of actions</li>
<li>We can learn incrementally without complete episodes</li>
</ol>
<p>The power of RL lies in learning optimal behavior without being explicitly told what to do - just by experiencing consequences and optimizing for long-term success.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/ieadoboe\.github\.io\/quarto-learn");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




<script src="../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>